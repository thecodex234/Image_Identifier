{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNAoJSNuDIx"
      },
      "outputs": [],
      "source": [
        "# Protoype 1\n",
        "# Control-click the file to see it.\n",
        "\"\"\"/content/chessiewow.jpeg\"\"\"\n",
        "\"\"\"/content/IMG_20241108_081319.jpg\"\"\"\n",
        "\"\"\"/content/IMG_20241108_081525.jpg\"\"\"\n",
        "\"\"\"/content/IMG_20241108_081707.jpg\"\"\"\n",
        "\"\"\"/content/cell_phone.png\"\"\"\n",
        "\"\"\"/content/floppy_disk.jpeg\"\"\"\n",
        "print(\"Please be patient. It will take a long time, around 50-70 seconds. It might work better with bigger and higher-quality images.\")\n",
        "path_to_image = input(\"Image path:\")\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tensorflow.keras.utils import plot_model # Ignore possible error\n",
        "import datetime\n",
        "\n",
        "# Load a pre-trained object detection model\n",
        "module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
        "\n",
        "detector = hub.load(module_handle).signatures['default']\n",
        "\n",
        "# Helper functions for image pre-processing and visualization\n",
        "\n",
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3) # Ignore error\n",
        "  return img\n",
        "\n",
        "def run_detector(detector, path):\n",
        "    img = load_img(path)\n",
        "\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    result = detector(converted_img)\n",
        "\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "    return img, result\n",
        "\n",
        "\n",
        "def display_image_with_boxes(img, result, threshold=0.1):\n",
        "    # Filter by threshold\n",
        "    high_confidence_indices = np.where(result['detection_scores'] > threshold)[0]\n",
        "\n",
        "    img_np = img.numpy().astype(np.uint8) # Convert image tensor to NumPy for OpenCV\n",
        "\n",
        "    for i in high_confidence_indices:\n",
        "        ymin, xmin, ymax, xmax = tuple(result['detection_boxes'][i])\n",
        "        class_id = result['detection_class_entities'][i].decode(\"ascii\")\n",
        "        score = result['detection_scores'][i]\n",
        "\n",
        "\n",
        "        # Calculate bounding box pixel coordinates\n",
        "        xmin = int(xmin * img_np.shape[1])\n",
        "        xmax = int(xmax * img_np.shape[1])\n",
        "        ymin = int(ymin * img_np.shape[0])\n",
        "        ymax = int(ymax * img_np.shape[0])\n",
        "\n",
        "        cv2.rectangle(img_np, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "        label = f\"{class_id}: {score:.2f}\"\n",
        "        cv2.putText(img_np, label, (xmin, ymin-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(img_np)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "image_path = path_to_image\n",
        "image, result = run_detector(detector, image_path)\n",
        "\n",
        "\n",
        "display_image_with_boxes(image, result, threshold=0.25)\n",
        "\n",
        "\n",
        "#-------------Tensorboard Logging-------------\n",
        "\n",
        "def create_summary_writers(log_dir):\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    train_log_dir = log_dir + current_time + '/train'\n",
        "    val_log_dir = log_dir + current_time + '/val'  # You'd use this if you were training\n",
        "\n",
        "    train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "    # val_summary_writer = tf.summary.create_file_writer(val_log_dir) # uncomment if needed\n",
        "\n",
        "    return train_summary_writer #, val_summary_writer\n",
        "\n",
        "\n",
        "log_dir = \"logs/\"  # Define your log directory\n",
        "train_summary_writer = create_summary_writers(log_dir)\n",
        "\n",
        "# Example of how to log an image to TensorBoard\n",
        "# This would typically happen in a training loop, but we demonstrate it here\n",
        "img_tensor = tf.image.convert_image_dtype(image, dtype=tf.uint8)  # Make sure it's uint8 for TensorBoard.\n",
        "with train_summary_writer.as_default():\n",
        "    tf.summary.image(\"Input Image\", img_tensor[tf.newaxis, ...], step=0)  # step=epoch or iteration number\n",
        "\n",
        "\n",
        "\n",
        "print(\"TensorBoard logs written to:\", log_dir)\n",
        "print(\"To view TensorBoard, run: tensorboard --logdir=\", log_dir)\n",
        "\n"
      ]
    }
  ]
}